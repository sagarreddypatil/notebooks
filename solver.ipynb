{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "\n",
    "w2v_model = gensim.downloader.load('word2vec-google-news-300')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def word2vec(word):\n",
    "    # return word2vec[word.lower().split()[-1]]\n",
    "    try:\n",
    "        return w2v_model[word.lower().split()[-1]]\n",
    "    except KeyError:\n",
    "        print(f\"Word {word} not found in word2vec\")\n",
    "        return w2v_model[\"hello\"]\n",
    "    \n",
    "def similarity(vec1: np.ndarray, vec2: np.ndarray):\n",
    "    # dot / (norm(vec1) * norm(vec2))\n",
    "    score = vec1.dot(vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "    # return max(0, score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch import Tensor\n",
    "\n",
    "model_name = \"thenlper/gte-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "sentenceformer = AutoModel.from_pretrained(model_name)\n",
    "sentenceformer.eval()\n",
    "\n",
    "def average_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "def word2vec(word):\n",
    "    encoded = tokenizer(word, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    model_output = sentenceformer(**encoded)\n",
    "    embedding = average_pool(model_output.last_hidden_state, encoded['attention_mask'])\n",
    "\n",
    "    return embedding.detach().numpy()[0]\n",
    "\n",
    "def similarity(vec1: np.ndarray, vec2: np.ndarray):\n",
    "    # dot / (norm(vec1) * norm(vec2))\n",
    "    return vec1.dot(vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "    # return vec1.dot(vec2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulator import NYTConnections\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from itertools import combinations\n",
    "from queue import PriorityQueue\n",
    "\n",
    "\n",
    "\n",
    "def solve(game: NYTConnections):\n",
    "    words = game.starting\n",
    "    vecs = {word: word2vec(word) for word in words}\n",
    "\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for pair in combinations(words, 2):\n",
    "        score = similarity(vecs[pair[0]], vecs[pair[1]])\n",
    "\n",
    "        G.add_edge(pair[0], pair[1], weight=score)\n",
    "\n",
    "    # add EVERY SINGLE 4-clique to a priority queue\n",
    "    pq = PriorityQueue()\n",
    "\n",
    "    for clique in combinations(G.nodes, 4):\n",
    "        clique = frozenset(clique)\n",
    "        sG = G.subgraph(clique)\n",
    "\n",
    "        # mod = nx.community.modularity(G, [clique]) * -1\n",
    "\n",
    "        within = 0\n",
    "\n",
    "        for edge in sG.edges:\n",
    "            within += G.get_edge_data(edge[0], edge[1])[\"weight\"]\n",
    "\n",
    "        without = 0\n",
    "        for edge in G.edges:\n",
    "            if len(clique.intersection(set(edge))) == 1:\n",
    "                without += G.get_edge_data(edge[0], edge[1])[\"weight\"] ** 2\n",
    "\n",
    "        # without = within - mod\n",
    "        mod = within - without  # modularity of the clique\n",
    "\n",
    "        pq.put((-mod, (set(clique), within, without)))\n",
    "\n",
    "    while not all(game.solved.values()):\n",
    "        # loop until we SOLVE the game\n",
    "\n",
    "        score, _guess = pq.get_nowait()  # [0] is the modularity score\n",
    "        guess, within, without = _guess\n",
    "        correct = game.guess(guess)\n",
    "\n",
    "        print(f\"Guessed {guess}: {correct}, score: {-score}, within: {within}, without: {without}\")\n",
    "\n",
    "        # if correct, remove all other cliques that contain the guess\n",
    "        if correct:\n",
    "            for clique in list(pq.queue):\n",
    "                if guess.intersection(clique[1][0]):\n",
    "                    pq.queue.remove(clique)\n",
    "\n",
    "    return game.mistakes_remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulator import NYTConnections\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def solve(game: NYTConnections):\n",
    "    words = game.starting\n",
    "    vecs = {word: word2vec(word) for word in words}\n",
    "    vecslist = list(vecs.values())\n",
    "\n",
    "    # distortions = []\n",
    "    # for k in range(1, 16):\n",
    "    #     kmeans = KMeans(n_clusters=k, n_init='auto')\n",
    "    #     kmeans.fit(vecslist)\n",
    "    #     distortions.append(kmeans.inertia_)\n",
    "\n",
    "    # fig = plt.figure(figsize=(15, 5))\n",
    "    # plt.plot(range(1, 16), distortions)\n",
    "    # plt.grid(True)\n",
    "    # plt.title(\"Elbow curve\")\n",
    "\n",
    "    clustering = KMeans(n_clusters=10, n_init='auto')\n",
    "    clustering.fit(vecslist)\n",
    "\n",
    "    clusters = {}\n",
    "\n",
    "    for i, label in enumerate(clustering.labels_):\n",
    "        if label not in clusters:\n",
    "            clusters[label] = []\n",
    "        \n",
    "        clusters[label].append(words[i])\n",
    "\n",
    "    print(clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: ['SWIFT', 'DASH', 'LARK', 'DART', 'BUMPER', 'JAY', 'HANCOCK'], 9: ['HOLIDAY'], 0: ['CARDINAL'], 2: ['HOOD'], 1: ['ZIP'], 6: ['MONK'], 8: ['TRUNK'], 4: ['PARKER'], 5: ['TIRE'], 7: ['BOLT']}\n",
      "Game 200: None mistakes remaining\n"
     ]
    }
   ],
   "source": [
    "mistake_counts = []\n",
    "\n",
    "for i in range(204, 205):\n",
    "    try:\n",
    "        game = NYTConnections(i)\n",
    "    except ValueError:\n",
    "        break\n",
    "    mistakes_remaining = solve(game)\n",
    "\n",
    "    mistake_counts.append(mistakes_remaining)\n",
    "    print(f\"Game {i}: {mistakes_remaining} mistakes remaining\")\n",
    "    # break\n",
    "\n",
    "\n",
    "# avg = sum(mistake_counts) / len(mistake_counts)\n",
    "# win_rate = sum([1 for count in mistake_counts if count >= 0]) / len(mistake_counts)\n",
    "# print(f\"Average mistakes remaining: {avg} for {len(mistake_counts)} games\")\n",
    "# print(f\"Win rate: {win_rate}\")\n",
    "# print(mistake_counts)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
